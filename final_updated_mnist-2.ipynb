{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "updated_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "qR1fYo7XJV3E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Importing the libraries\n",
        "import numpy  as np  \n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import keras\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MZ0o1hIuzr9x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wwmCcJqoJ6z6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Loading the data\n",
        "x_train_images = pd.read_pickle('drive/My Drive/ML_miniproject_3/train_images.pkl')\n",
        "x_test_images  = pd.read_pickle('drive/My Drive/ML_miniproject_3/test_images.pkl')\n",
        "y_train_labels = pd.read_csv('drive/My Drive/ML_miniproject_3/train_labels.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qb-TkVT80nBI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Displaying the image\n",
        "for id in range(1):   \n",
        "    plt.title('Label: {}'.format(y_train_labels.iloc[id]['Category']))\n",
        "    plt.imshow(x_train_images[id], cmap='gray')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iVykEr7kJ7zX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reshaping the data for processing\n",
        "X_train = x_train_images.reshape(-1, 64, 64) # reshape \n",
        "X_test = x_test_images.reshape(-1, 64, 64) # reshape\n",
        "Y_train = y_train_labels['Category']\n",
        "Y_train = Y_train.values.reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "97pBac3RKAdB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This function gets the bounding boxes around each digit\n",
        "def bounding_box(x):\n",
        "    box = []\n",
        "    for i in range(x.shape[0]):\n",
        "        image = x[i].copy()\n",
        "\n",
        "        # threshold and find contours\n",
        "        # ret value set to threshold of 254\n",
        "        ret, thresh = cv2.threshold(image,254,255,0)\n",
        "        imagecon, contours, hierarchy = cv2.findContours(np.uint8(thresh), 0, 2)\n",
        "\n",
        "        # finding minimum area rectangle covering contour\n",
        "        min_area = []\n",
        "        for c in contours:\n",
        "            rect = cv2.minAreaRect(c)\n",
        "            pos, size, orientation = rect\n",
        "            area = max(size[0],size[1])**2\n",
        "            # discarding boxes that cannot be possibly a digit\n",
        "            if area > 49:\n",
        "                min_area.append((area,[pos[0],pos[1],size[0],size[1],orientation]))\n",
        "        \n",
        "        # sorting the area, from largest\n",
        "        min_area.sort(key=lambda x: x[0], reverse=True)\n",
        "        min_area = list(list(zip(*min_area))[1])\n",
        "        box.append(min_area)\n",
        "    \n",
        "    return box"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AcXAqA50KFNv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This function return coordinates of box around each digit\n",
        "def coordinate(img, bounding_box, offset=0):\n",
        "    _, image_threshold = cv2.threshold(img, 254, 255, 0)\n",
        "    x_pos, y_pos, width, height, orientation = bounding_box\n",
        "    box = cv2.boxPoints(((x_pos, y_pos), (width, height), orientation))\n",
        "    box = np.int0(box)\n",
        "\n",
        "    x_min = max(min(box[:,0]), 0)\n",
        "    x_max = min(max(box[:,0]), image_threshold.shape[0])\n",
        "    y_min = max(min(box[:,1]), 0)\n",
        "    y_max = min(max(box[:,1]), image_threshold.shape[0])\n",
        "    \n",
        "    # bounding box without orientation\n",
        "    digit = image_threshold[y_min:y_max, x_min:x_max].copy()\n",
        "    \n",
        "    # tightening up the bounding box \n",
        "    sum_x     = np.sum(digit,axis=0)\n",
        "    nonzero_x = np.nonzero(sum_x)\n",
        "    x_min    += np.amin(nonzero_x)\n",
        "    x_max    -= (digit.shape[1] - np.amax(nonzero_x))\n",
        "\n",
        "    sum_y     = np.sum(digit,axis=1)\n",
        "    nonzero_y = np.nonzero(sum_y)\n",
        "    y_min    += np.amin(nonzero_y)\n",
        "    y_max    -= (digit.shape[0] - np.amax(nonzero_y))\n",
        "    \n",
        "    x_min = max(x_min-offset,0)\n",
        "    x_max = min(x_max+offset,image_threshold.shape[0])\n",
        "    y_min = max(y_min-offset,0)\n",
        "    y_max = min(y_max+offset,image_threshold.shape[0])\n",
        "    \n",
        "    width  = x_max-x_min\n",
        "    height = y_max-y_min\n",
        "    \n",
        "    return x_min, y_min, width, height"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6NYMBPYFKJrX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Oriented bounding boxes for all digits\n",
        "\n",
        "def preprocess(Image):\n",
        "  \n",
        "  box_train = bounding_box(Image)\n",
        "  original_x = []\n",
        "  proc_x = []\n",
        "  proc_y = []\n",
        "  box_train_proc =[]\n",
        "  \n",
        "  for i in range(Image.shape[0]):\n",
        "\n",
        "      # there cannot be possibly a single digit, hence discard\n",
        "      x, y, width, height, _ = box_train[i][0]\n",
        "      if width >= 64 or height >= 64:\n",
        "        print(i)\n",
        "        continue\n",
        "\n",
        "      # getting un-rotated digit and threshold\n",
        "      x, y, w, h      = coordinate(Image[i], box_train[i][0])\n",
        "      x, y, w, h      = int(x),int(y),int(w),int(h)\n",
        "      _, image_thresh = cv2.threshold(Image[i, y:y+h, x:x+w], 254, 255, 0)  \n",
        "\n",
        "      # padding for a square...\n",
        "      max_width_height = max(w,h)\n",
        "      if max_width_height > w:\n",
        "        padding      = int((max_width_height-w)/2)\n",
        "        image_thresh = np.pad(image_thresh, ((0,0),(padding,padding)), 'constant', constant_values=0)\n",
        "      elif max_width_height > h:\n",
        "        pad_amt      = int((max_width_height-h)/2)\n",
        "        image_thresh = np.pad(image_thresh, ((padding,padding),(0,0)), 'constant', constant_values=0)\n",
        "\n",
        "      # padding to have a border of two pixels of 28\n",
        "      image_thresh = np.pad(image_thresh, 2, 'constant', constant_values=0)\n",
        "      image_thresh = cv2.resize(image_thresh, (28,28))\n",
        "\n",
        "      original_x.append(Image[i])\n",
        "      proc_x.append(image_thresh)\n",
        "      proc_y.append(Y_train[i])\n",
        "      box_train_proc.append(box_train[i])\n",
        "\n",
        "  original_x     = np.array(original_x)\n",
        "  proc_x         = np.expand_dims(np.array(proc_x),axis=1)\n",
        "  proc_y         = np.array(proc_y)\n",
        "  box_train_proc = np.array(box_train_proc)\n",
        "\n",
        "  \n",
        "  return proc_x, proc_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DRN_OkmKKQkG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Preprocessing of the training and testing images\n",
        "X_train_processed, Y_train_processed = preprocess(X_train) \n",
        "X_test_processed, temp               = preprocess(X_test)\n",
        "del(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hj9knUbE0sUj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Display the processed training and testing image\n",
        "X_train_plot = X_train_processed.reshape(40000,28,28)\n",
        "print(X_train_plot.shape)\n",
        "print(\"Processed training images...\")\n",
        "for id in range(3):   \n",
        "    plt.title('Label: {}'.format(y_train_labels.iloc[id]['Category']))\n",
        "    plt.imshow(X_train_plot[id], cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "X_test_plot = X_test_processed.reshape(10000,28,28)\n",
        "print(X_test_plot.shape)\n",
        "print(\"Processed training images...\")\n",
        "for id in range(5):   \n",
        "    plt.imshow(X_test_plot[id], cmap='gray')\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nSloYQcuKSSo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Second processing of the images\n",
        "preX_train, preX_test= [],[]\n",
        "\n",
        "# Normalising the images\n",
        "X_train_processed_N = X_train_processed/255\n",
        "X_test_processed_N  = X_test_processed/255\n",
        "\n",
        "#Training set\n",
        "for image in X_train_processed_N:\n",
        "    reshaped = image.reshape((784))\n",
        "    preX_train.append(reshaped)\n",
        "    \n",
        "#Test set\n",
        "for image in X_test_processed_N:\n",
        "    reshaped = image.reshape((784))\n",
        "    preX_test.append(reshaped)\n",
        "\n",
        "\n",
        "preX_train = np.array(preX_train)\n",
        "preX_test  = np.array(preX_test)\n",
        "\n",
        "x_train = preX_train[:37500]\n",
        "y_train = Y_train[:37500]\n",
        "x_valid = preX_train[37500:]\n",
        "y_valid = Y_train[37500:]\n",
        "x_test  = preX_test\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28,1).astype('float32')\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], 28, 28,1).astype('float32')\n",
        "x_test  = x_test.reshape(x_test.shape[0], 28, 28,1).astype('float32')\n",
        "\n",
        "# Fitting the model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from  keras.utils import np_utils\n",
        "y_binary = np_utils.to_categorical(y_train)\n",
        "y_valid_binary= np_utils.to_categorical(y_valid)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BRiddxS7LsfP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import LearningRateScheduler,ReduceLROnPlateau\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "datagen.fit(x_train)\n",
        "\n",
        "#Callbacks\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                                patience=5, \n",
        "                                                verbose=1, \n",
        "                                                factor=0.5, \n",
        "                                                min_lr=0.0001)\n",
        "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "99nL4l08Kv64",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Update the parameter values \n",
        "num_classes = 10\n",
        "n_epochs = 15 \n",
        "batch_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9E1o6IopW696",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#vgg5 Model\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras import backend as K\n",
        "from keras.layers import Conv2D, MaxPooling2D,Activation,BatchNormalization\n",
        "\n",
        "def CNN_model():\n",
        " \n",
        "  # creating the model\n",
        "  model = Sequential()\n",
        "  \n",
        "  #1st 2 layer\n",
        "  model.add(Conv2D(64, (3, 3), input_shape=(28, 28,1), activation=None, padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  \n",
        "  model.add(Conv2D(64, (3, 3), activation=None, padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  \n",
        "  model.add(MaxPooling2D((2, 2), strides=(2,2)))\n",
        "  \n",
        "  #2nd two layer\n",
        "  model.add(Conv2D(128, (3, 3), activation=None, padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  \n",
        "  model.add(Conv2D(128, (3, 3), activation=None, padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  \n",
        "  model.add(MaxPooling2D((2, 2), strides=(2,2)))\n",
        "  \n",
        "  #1st 3 layer\n",
        "  model.add(Conv2D(256, (3, 3), activation=None, padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  \n",
        "  model.add(Conv2D(256, (3,3), activation=None, padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  \n",
        "  model.add(Conv2D(256, (3, 3), activation=None, padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  \n",
        "  model.add(MaxPooling2D((2, 2), strides=(2,2)))\n",
        "  \n",
        "  #2st 3 layer\n",
        "  model.add(Conv2D(512, (3, 3), activation=None, padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  \n",
        "  model.add(Conv2D(512, (3, 3), activation=None, padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  \n",
        "  model.add(Conv2D(512, (3,3), activation=None, padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  \n",
        "  model.add(MaxPooling2D((2, 2), strides=(2,2)))\n",
        " \n",
        "  \n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  \n",
        "  # Compiling the model\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4KOiUcW1Ka5O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        },
        "outputId": "b873f7e0-afa8-4fa6-e539-f02e9b075284"
      },
      "cell_type": "code",
      "source": [
        "model1 = CNN_model()\n",
        "filepath=\"best_weights1.hdf5\"\n",
        "checkpoint1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "history1 = model1.fit_generator(datagen.flow(x_train, y_binary, batch_size=batch_size),\n",
        "                              steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                              validation_data=(x_valid, y_valid_binary),\n",
        "                              epochs = 2, callbacks=[learning_rate_reduction, checkpoint1])\n",
        "                   "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/2\n",
            "292/292 [==============================] - 45s 155ms/step - loss: 0.7462 - acc: 0.7779 - val_loss: 0.7082 - val_acc: 0.8168\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.81680, saving model to best_weights1.hdf5\n",
            "Epoch 2/2\n",
            "292/292 [==============================] - 39s 133ms/step - loss: 0.3535 - acc: 0.9094 - val_loss: 0.6946 - val_acc: 0.8372\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.81680 to 0.83720, saving model to best_weights1.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vsU9f6eo6NE-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#source: https://github.com/CodeRiderViru/Hand-written-digit-recognition-/blob/master/mnist.ipynb\n",
        "\n",
        "def CNN():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3),activation='relu',input_shape=(28,28,1)))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3),activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.20))\n",
        "    \n",
        "    model.add(Conv2D(128, (3, 3), activation='relu',padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu',padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Conv2D(128, (3, 3), activation='relu',padding='same'))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    \n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fpXcKE3R6aeZ",
        "colab_type": "code",
        "outputId": "0a0e6d7a-4556-483d-ea38-6cd23969b4da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2111
        }
      },
      "cell_type": "code",
      "source": [
        "model2 = CNN()\n",
        "filepath=\"best_weights2.hdf5\"\n",
        "checkpoint2 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "history2 = model2.fit_generator(datagen.flow(x_train,y_binary, batch_size=batch_size),steps_per_epoch=(len(x_train)//batch_size),\n",
        "                               epochs = 30, validation_data = (x_valid,y_valid_binary),\n",
        "                               callbacks=[learning_rate_reduction, checkpoint2])\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "292/292 [==============================] - 20s 67ms/step - loss: 0.9380 - acc: 0.7051 - val_loss: 0.4148 - val_acc: 0.8984\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.89840, saving model to best_weights2.hdf5\n",
            "Epoch 2/30\n",
            "292/292 [==============================] - 17s 57ms/step - loss: 0.4596 - acc: 0.8809 - val_loss: 0.3693 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.89840 to 0.92160, saving model to best_weights2.hdf5\n",
            "Epoch 3/30\n",
            "292/292 [==============================] - 16s 56ms/step - loss: 0.3960 - acc: 0.9016 - val_loss: 0.3527 - val_acc: 0.9276\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.92160 to 0.92760, saving model to best_weights2.hdf5\n",
            "Epoch 4/30\n",
            "292/292 [==============================] - 16s 56ms/step - loss: 0.3620 - acc: 0.9106 - val_loss: 0.3552 - val_acc: 0.9260\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.92760\n",
            "Epoch 5/30\n",
            "292/292 [==============================] - 17s 57ms/step - loss: 0.3418 - acc: 0.9157 - val_loss: 0.3258 - val_acc: 0.9272\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.92760\n",
            "Epoch 6/30\n",
            "292/292 [==============================] - 17s 57ms/step - loss: 0.3280 - acc: 0.9208 - val_loss: 0.3242 - val_acc: 0.9300\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.92760 to 0.93000, saving model to best_weights2.hdf5\n",
            "Epoch 7/30\n",
            "292/292 [==============================] - 17s 57ms/step - loss: 0.3151 - acc: 0.9245 - val_loss: 0.3149 - val_acc: 0.9352\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.93000 to 0.93520, saving model to best_weights2.hdf5\n",
            "Epoch 8/30\n",
            "292/292 [==============================] - 17s 58ms/step - loss: 0.3013 - acc: 0.9285 - val_loss: 0.3278 - val_acc: 0.9344\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.93520\n",
            "Epoch 9/30\n",
            "292/292 [==============================] - 17s 57ms/step - loss: 0.2949 - acc: 0.9296 - val_loss: 0.3081 - val_acc: 0.9400\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.93520 to 0.94000, saving model to best_weights2.hdf5\n",
            "Epoch 10/30\n",
            "292/292 [==============================] - 16s 56ms/step - loss: 0.2841 - acc: 0.9318 - val_loss: 0.3241 - val_acc: 0.9396\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.94000\n",
            "Epoch 11/30\n",
            "292/292 [==============================] - 17s 57ms/step - loss: 0.2776 - acc: 0.9342 - val_loss: 0.3225 - val_acc: 0.9368\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.94000\n",
            "Epoch 12/30\n",
            "292/292 [==============================] - 17s 57ms/step - loss: 0.2728 - acc: 0.9348 - val_loss: 0.2856 - val_acc: 0.9392\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.94000\n",
            "Epoch 13/30\n",
            "292/292 [==============================] - 16s 56ms/step - loss: 0.2684 - acc: 0.9379 - val_loss: 0.2968 - val_acc: 0.9404\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.94000 to 0.94040, saving model to best_weights2.hdf5\n",
            "Epoch 14/30\n",
            "292/292 [==============================] - 17s 58ms/step - loss: 0.2634 - acc: 0.9372 - val_loss: 0.2994 - val_acc: 0.9412\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.94040 to 0.94120, saving model to best_weights2.hdf5\n",
            "Epoch 15/30\n",
            "292/292 [==============================] - 17s 57ms/step - loss: 0.2567 - acc: 0.9386 - val_loss: 0.2839 - val_acc: 0.9404\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.94120\n",
            "Epoch 16/30\n",
            "292/292 [==============================] - 16s 56ms/step - loss: 0.2555 - acc: 0.9393 - val_loss: 0.3150 - val_acc: 0.9396\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.94120\n",
            "Epoch 17/30\n",
            "292/292 [==============================] - 17s 58ms/step - loss: 0.2467 - acc: 0.9406 - val_loss: 0.3079 - val_acc: 0.9416\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.94120 to 0.94160, saving model to best_weights2.hdf5\n",
            "Epoch 18/30\n",
            "292/292 [==============================] - 16s 56ms/step - loss: 0.2480 - acc: 0.9410 - val_loss: 0.3057 - val_acc: 0.9416\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.94160\n",
            "Epoch 19/30\n",
            "292/292 [==============================] - 16s 56ms/step - loss: 0.2426 - acc: 0.9408 - val_loss: 0.2958 - val_acc: 0.9392\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.94160\n",
            "Epoch 20/30\n",
            "292/292 [==============================] - 17s 57ms/step - loss: 0.2417 - acc: 0.9436 - val_loss: 0.3025 - val_acc: 0.9404\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.94160\n",
            "Epoch 21/30\n",
            "292/292 [==============================] - 16s 56ms/step - loss: 0.2373 - acc: 0.9435 - val_loss: 0.2884 - val_acc: 0.9428\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.94160 to 0.94280, saving model to best_weights2.hdf5\n",
            "Epoch 22/30\n",
            "292/292 [==============================] - 16s 56ms/step - loss: 0.2338 - acc: 0.9452 - val_loss: 0.2880 - val_acc: 0.9440\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.94280 to 0.94400, saving model to best_weights2.hdf5\n",
            "Epoch 23/30\n",
            "292/292 [==============================] - 17s 57ms/step - loss: 0.2349 - acc: 0.9446 - val_loss: 0.2815 - val_acc: 0.9416\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.94400\n",
            "Epoch 24/30\n",
            "292/292 [==============================] - 16s 56ms/step - loss: 0.2249 - acc: 0.9470 - val_loss: 0.2980 - val_acc: 0.9424\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.94400\n",
            "Epoch 25/30\n",
            "292/292 [==============================] - 17s 57ms/step - loss: 0.2235 - acc: 0.9470 - val_loss: 0.3173 - val_acc: 0.9416\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.94400\n",
            "Epoch 26/30\n",
            "292/292 [==============================] - 17s 58ms/step - loss: 0.2207 - acc: 0.9467 - val_loss: 0.3081 - val_acc: 0.9404\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.94400\n",
            "Epoch 27/30\n",
            "292/292 [==============================] - 17s 57ms/step - loss: 0.2199 - acc: 0.9461 - val_loss: 0.3058 - val_acc: 0.9440\n",
            "\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.94400\n",
            "Epoch 28/30\n",
            "292/292 [==============================] - 16s 56ms/step - loss: 0.2030 - acc: 0.9522 - val_loss: 0.2924 - val_acc: 0.9412\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.94400\n",
            "Epoch 29/30\n",
            "292/292 [==============================] - 17s 57ms/step - loss: 0.2001 - acc: 0.9532 - val_loss: 0.2933 - val_acc: 0.9436\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.94400\n",
            "Epoch 30/30\n",
            "292/292 [==============================] - 17s 57ms/step - loss: 0.1945 - acc: 0.9531 - val_loss: 0.3055 - val_acc: 0.9460\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.94400 to 0.94600, saving model to best_weights2.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LZQp-kdAMQ0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81917078-26d8-4b9f-b351-a379fbabcc00"
      },
      "cell_type": "code",
      "source": [
        "model1.load_weights(\"best_weights1.hdf5\")\n",
        "Accuracy = model1.evaluate(x_valid, y_valid_binary, verbose=0)\n",
        "print(\"Deep CNN Accuracy: %.2f%%\" % (Accuracy[1]*100))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deep CNN Accuracy: 83.72%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EOMlsmbeFe6D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58e23854-cfb6-4435-f261-de592df89b97"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model2.load_weights(\"best_weights2.hdf5\")\n",
        "Accuracy = model2.evaluate(x_valid, y_valid_binary, verbose=0)\n",
        "print(\"Deep CNN Accuracy: %.2f%%\" % (Accuracy[1]*100))\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deep CNN Accuracy: 94.60%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D2jigRyjxiP7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "018ceb7e-816c-48fd-f719-903f8f324c68"
      },
      "cell_type": "code",
      "source": [
        "results = np.zeros( (x_valid.shape[0],10) )\n",
        "#results = results + model1.predict(x_valid) #x_val\n",
        "results = results + model2.predict(x_valid) #x_val\n",
        "#results = results + model3.predict(x_test) #x_val\n",
        "#results = results + model4.predict(x_test) #x_val\n",
        "#results = results + model5.predict(x_test) #x_val\n",
        "results = np.argmax(results,axis = 1)\n",
        "results = pd.Series(results,name=\"Label\")\n",
        "y_valid_binary[0].shape\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "QkacSks1Qvr4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "accuracy_score(results,y_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VuUJuWKBMwth",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results = np.zeros( (x_test.shape[0],10) )\n",
        "#results = results + model1.predict(x_test) #x_val\n",
        "results = results + model2.predict(x_test) #x_val\n",
        "#results = results + model3.predict(x_test) #x_val\n",
        "#results = results + model4.predict(x_test) #x_val\n",
        "#results = results + model5.predict(x_test) #x_val\n",
        "results = np.argmax(results,axis = 1)\n",
        "results = pd.Series(results,name=\"Label\")\n",
        "submission = pd.DataFrame({'ImageId': np.arange(1, len(results)+1), 'Label': results})\n",
        "submission.to_csv('submission_0.05.csv', index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rmk82-HJAzZ5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "eRU8YGWiWwgj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Accuracy = model.evaluate(x_valid, y_valid_binary, verbose=0)\n",
        "print(\"Deep CNN Accuracy: %.2f%%\" % (Accuracy[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}